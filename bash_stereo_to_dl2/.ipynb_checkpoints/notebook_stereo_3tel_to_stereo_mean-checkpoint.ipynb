{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc0115af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- packages --- #\n",
    "import numpy  as np \n",
    "import pandas as pd\n",
    "import os, sys, glob\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None) # to show all columns when displaying dataframes\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# location of the scripts\n",
    "sys.path.insert(0, '/fefs/aswg/workspace/juan.jimenez/stereo_analysis/scripts')\n",
    "import auxiliar as aux\n",
    "import merge \n",
    "\n",
    "from magicctapipe.io import get_dl2_mean\n",
    "\n",
    "# --- source we are going to analyse --- #\n",
    "source_name = 'Crab'\n",
    "\n",
    "#############################\n",
    "# ------- parameters ------ #\n",
    "#############################\n",
    "# --- wheigth type used --- #\n",
    "# simple, variance or intesity\n",
    "weight_type = 'variance'\n",
    "\n",
    "# --- directories --- #\n",
    "common_data_file  = '/fefs/aswg/workspace/juan.jimenez/stereo_analysis/config_files/common_data.txt'\n",
    "main_dir          = '/fefs/aswg/workspace/juan.jimenez/data/dl2'\n",
    "stereo_dl2_dir        = os.path.join(main_dir, f'stereo_raw_dl2_{source_name}')\n",
    "\n",
    "stereo_dl2_merged_dir = os.path.join(main_dir, f'stereo_merged_{source_name}')\n",
    "stereo_dl2_mean_dir   = os.path.join(main_dir, f'stereo_mean')\n",
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc08a6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c0af961",
   "metadata": {},
   "source": [
    "## Create/finding directories and files-runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcca9aef",
   "metadata": {},
   "source": [
    "## Saving all in a unique dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a973bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = False\n",
    "combo_types = False\n",
    "\n",
    "step = 0\n",
    "\n",
    "# creating folders\n",
    "aux.createdir(stereo_dl2_merged_dir)\n",
    "aux.createdir(stereo_dl2_mean_dir)\n",
    "\n",
    "########################################\n",
    "# --- converting to totaldataframe --- #\n",
    "########################################\n",
    "# reading dataframes and putting all together into a unique dataframe\n",
    "# --- converting to unique dataframe --- #\n",
    "if merge:\n",
    "    merge.stereo_dl2(input_dir=stereo_dl2_dir, output_dir=stereo_dl2_merged_dir)\n",
    "\n",
    "# now we read the file\n",
    "# first of all we find the file\n",
    "merged_files = glob.glob(os.path.join(stereo_dl2_merged_dir,'*'))\n",
    "merged_file  = [f for f in merged_files if '_to_' in f][0]\n",
    "\n",
    "# reading the dataframe\n",
    "df_total = pd.read_hdf(merged_file, key='events/parameters')\n",
    "df_total.set_index(['obs_id', 'event_id', 'tel_id'], inplace=True)\n",
    "df_total.sort_index(inplace=True)\n",
    "########################################          \n",
    "\n",
    "df_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191fb92",
   "metadata": {},
   "source": [
    "## Segment the data in combo types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa883de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# --- filtering by combo types --- #\n",
    "####################################\n",
    "if combo_types:\n",
    "\n",
    "    # calculating merged dataframes with combo types\n",
    "    df_merged = [df_total.query(f'combo_type == {ctype}', inplace=False) for ctype in [3, 0, 1, 2]]\n",
    "\n",
    "    # number of events and statistics\n",
    "    nevents3, nevents0 = int(len(df_merged[0])/3), int(len(df_merged[1])/2)\n",
    "    nevents1, nevents2 = int(len(df_merged[2])/2), int(len(df_merged[3])/2)\n",
    "\n",
    "    neventstotal = nevents3 + nevents0 + nevents1 + nevents2 \n",
    "    print(f'\\n3-Telescopes events filtering\\nPassing from {neventstotal} events to...')\n",
    "    print(f'LST1 + MI + MII --> to {nevents3} events,\\t{nevents3 / neventstotal * 100:.2f}% conserved')\n",
    "    print(f'MI + MII        --> to {nevents0} events,\\t{nevents0 / neventstotal * 100:.2f}% conserved')\n",
    "    print(f'LST1 + MI       --> to {nevents1} events,\\t{nevents1 / neventstotal * 100:.2f}% conserved')\n",
    "    print(f'LST1 + MII      --> to {nevents2} events,\\t{nevents2 / neventstotal * 100:.2f}% conserved')\n",
    "\n",
    "\n",
    "    for name, i in zip(['3tel', 'MI_MII', 'LST1_MI', 'LST1_MII'][:1], range(len(df_merged[:1]))):\n",
    "\n",
    "        # --- creating a unique identification --- #\n",
    "        print(f'\\nCreating a unique \\'run.event\\' identification label')\n",
    "        # extracting indexes, runs and events\n",
    "        obs_id_array   = np.array(df_merged[i].index.get_level_values('obs_id').values).astype(str)\n",
    "        event_id_array = np.array(df_merged[i].index.get_level_values('event_id').values).astype(str)\n",
    "        universal_id = np.char.add(obs_id_array, np.char.add('.',event_id_array))\n",
    "\n",
    "        obs_id_array_magic   = df_merged[i]['obs_id_magic'].to_numpy().astype(str)\n",
    "        event_id_array_magic = df_merged[i]['event_id_magic'].to_numpy().astype(str)\n",
    "        universal_id_magic = np.char.add(obs_id_array_magic, np.char.add('.',event_id_array_magic))\n",
    "\n",
    "        df_merged[i].loc[:, 'total_id'] = universal_id\n",
    "        df_merged[i].loc[:, 'magic_id'] = universal_id_magic  \n",
    "\n",
    "        df_merged[i].to_hdf(f'{stereo_dl2_merged_dir}/dl2_merged_{source_name}_total.{name}.h5', key='events/parameters')\n",
    "\n",
    "    df_total.to_hdf(f'{stereo_dl2_merged_dir}/dl2_merged_{source_name}_total.all_combo.h5', key='events/parameters')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb2d2db",
   "metadata": {},
   "source": [
    "# Calculating mean dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a6bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df_total, df_total.query(f'combo_type == {3}', inplace=False)]\n",
    "name = ['all_combo', '3tel']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c18dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# --- for all telescopes --- #\n",
    "##############################\n",
    "# calculating means\n",
    "print(f'Calculating means for all telescopes and {name[step]} events')      \n",
    "df_mean = get_dl2_mean(dfs[step])\n",
    "\n",
    "# --- creating a unique identification --- #               \n",
    "obs_id_array   = np.array(df_mean.index.get_level_values('obs_id').values).astype(str)\n",
    "event_id_array = np.array(df_mean.index.get_level_values('event_id').values).astype(str)\n",
    "universal_id = np.char.add(obs_id_array, np.char.add('.',event_id_array))\n",
    "df_mean.loc[:, 'total_id'] = universal_id\n",
    "\n",
    "# --- create .h5 file --- #\n",
    "print('Creating .h5 file\\n')\n",
    "df_mean.to_hdf(f'{stereo_dl2_mean_dir}/dl2_mean_{source_name}_total.{name[step]}.h5', key='events/parameters')\n",
    "##############################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fe1e4b",
   "metadata": {},
   "source": [
    "## Mean dataframes for LST and MAGIC only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f30de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# -------- for LST --------- #\n",
    "##############################\n",
    "# calculating means\n",
    "print(f'Calculating means for LST and {name[step]} events')  \n",
    "df_tmp_LST = dfs[step].query('tel_id == 1', inplace=False)\n",
    "df_mean = get_dl2_mean(df_tem_LST)\n",
    "\n",
    "# --- creating a unique identification --- #               \n",
    "obs_id_array   = np.array(df_mean.index.get_level_values('obs_id').values).astype(str)\n",
    "event_id_array = np.array(df_mean.index.get_level_values('event_id').values).astype(str)\n",
    "universal_id = np.char.add(obs_id_array, np.char.add('.',event_id_array))\n",
    "df_mean.loc[:, 'total_id'] = universal_id\n",
    "\n",
    "# --- create .h5 file --- #\n",
    "print('Creating .h5 file\\n')\n",
    "df_mean.to_hdf(f'{stereo_dl2_mean_dir}/dl2_mean_{source_name}_LST.{name[step]}.h5', key='events/parameters')\n",
    "df_tmp_LST.to_hdf(f'{stereo_dl2_merged_dir}/dl2_merged_{source_name}_LST.{name[step]}.h5', key='events/parameters')\n",
    "##############################\n",
    "\n",
    "\n",
    "##############################\n",
    "# ------- for MAGIC -------- #\n",
    "##############################\n",
    "# calculating means\n",
    "print(f'Calculating means for MAGIC and {name[step]} events')  \n",
    "df_tmp_MAGIC = dfs[step].query('tel_id == 2 | tel_id == 3', inplace=False)\n",
    "df_mean = get_dl2_mean(df_tmp_MAGIC)\n",
    "\n",
    "# --- creating a unique identification --- #               \n",
    "obs_id_array   = np.array(df_mean.index.get_level_values('obs_id').values).astype(str)\n",
    "event_id_array = np.array(df_mean.index.get_level_values('event_id').values).astype(str)\n",
    "universal_id = np.char.add(obs_id_array, np.char.add('.',event_id_array))\n",
    "df_mean.loc[:, 'total_id'] = universal_id\n",
    "\n",
    "# --- create .h5 file --- #\n",
    "print('Creating .h5 file\\n')\n",
    "df_mean.to_hdf(f'{stereo_dl2_mean_dir}/dl2_mean_{source_name}_MAGIC.{name[step]}.h5', key='events/parameters')\n",
    "df_tmp_MAGIC.to_hdf(f'{stereo_dl2_merged_dir}/dl2_merged_{source_name}_MAGIC.{name[step]}.h5', key='events/parameters')\n",
    "##############################    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ab5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
