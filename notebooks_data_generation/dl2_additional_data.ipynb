{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b29659bd",
   "metadata": {},
   "source": [
    "Import packages and setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c03ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Study of the source: BLLac\n",
      "\n",
      "All data taken from the main path /fefs/aswg/workspace/juan.jimenez/data\n",
      "\n",
      "\n",
      "--> The selected number of OFF regions is 5\n",
      "\n",
      "--> Computing RA and DEC of LST-lstchain files: True\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, logging, sys, glob\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# --- logging --- #\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# location of the scripts\n",
    "sys.path.insert(0, '/fefs/aswg/workspace/juan.jimenez/stereo_analysis/scripts')\n",
    "import auxiliar as aux\n",
    "import geometry as geom\n",
    "aux.params()\n",
    "\n",
    "from astropy.coordinates import AltAz, SkyCoord, EarthLocation, ICRS\n",
    "from ctapipe.coordinates import CameraFrame\n",
    "from lstchain.reco.utils import compute_theta2, extract_source_position, clip_alt\n",
    "from magicctapipe.utils  import calculate_off_coordinates\n",
    "from astropy import units as u\n",
    "\n",
    "# --- other parameters --- #\n",
    "# name of the source we are studying\n",
    "source_name = 'BLLac'\n",
    "# number of off regions\n",
    "n_regions_off  = 5\n",
    "# if we want to compute the RA and DEC information for the runs that do not have it\n",
    "# if done, set to False because is along process ~1.5h\n",
    "compute_ra_dec = True\n",
    "# ------------------------ #\n",
    "\n",
    "# --- file paths --- #\n",
    "root_path = '/fefs/aswg/workspace/juan.jimenez/data'\n",
    "\n",
    "merged_path  = f'{root_path}/dl2/stereo_merged_{source_name}/*'\n",
    "mean_path    = f'{root_path}/dl2/stereo_mean/*{source_name}*'\n",
    "lst_path     = f'{root_path}/dl2/lst/*'\n",
    "melibea_path = f'{root_path}/dl2/melibea/*'\n",
    "# ------------------ #\n",
    "\n",
    "logger.info(f'Study of the source: {source_name}')\n",
    "logger.info(f'\\nAll data taken from the main path {root_path}')\n",
    "logger.info(f'\\n\\n--> The selected number of OFF regions is {n_regions_off}')\n",
    "logger.info(f'\\n--> Computing RA and DEC of LST-lstchain files: {compute_ra_dec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58ca0d2",
   "metadata": {},
   "source": [
    "All the data we have at the directories is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b830a9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The merged files are taken from /fefs/aswg/workspace/juan.jimenez/data/dl2/stereo_merged_BLLac/*, and 7 are found:\n",
      "--> /fefs/aswg/workspace/juan.jimenez/data/dl2/stereo_merged_BLLac/dl2_merged_BLLac_total.MI_MII.h5\n",
      "--> /fefs/aswg/workspace/juan.jimenez/data/dl2/stereo_merged_BLLac/dl2_merged_BLLac_MAGIC.3tel.h5\n",
      "--> /fefs/aswg/workspace/juan.jimenez/data/dl2/stereo_merged_BLLac/dl2_merged_BLLac_total.3tel.h5\n",
      "--> /fefs/aswg/workspace/juan.jimenez/data/dl2/stereo_merged_BLLac/dl2_merged_BLLac_total.LST1_MI.h5\n",
      "--> /fefs/aswg/workspace/juan.jimenez/data/dl2/stereo_merged_BLLac/dl2_merged_BLLac_LST.3tel.h5\n",
      "--> /fefs/aswg/workspace/juan.jimenez/data/dl2/stereo_merged_BLLac/dl2_merged_BLLac_total.all_combo.h5\n",
      "--> /fefs/aswg/workspace/juan.jimenez/data/dl2/stereo_merged_BLLac/dl2_merged_BLLac_total.LST1_MII.h5\n",
      "\n",
      "\n",
      "The mean files are taken from /fefs/aswg/workspace/juan.jimenez/data/dl2/stereo_mean/*BLLac*, and 3 are found:\n",
      "--> /fefs/aswg/workspace/juan.jimenez/data/dl2/stereo_mean/dl2_mean_BLLac_total.3tel.h5\n",
      "--> /fefs/aswg/workspace/juan.jimenez/data/dl2/stereo_mean/dl2_mean_BLLac_LST.3tel.h5\n",
      "--> /fefs/aswg/workspace/juan.jimenez/data/dl2/stereo_mean/dl2_mean_BLLac_MAGIC.3tel.h5\n",
      "\n",
      "\n",
      "The lst-only files are taken from /fefs/aswg/workspace/juan.jimenez/data/dl2/lst/*, and 1 are found:\n",
      "--> /fefs/aswg/workspace/juan.jimenez/data/dl2/lst/dl2_lst_Crab.h5\n",
      "\n",
      "\n",
      "The melibea-only files are taken from /fefs/aswg/workspace/juan.jimenez/data/dl2/melibea/*, and 2 are found:\n",
      "--> /fefs/aswg/workspace/juan.jimenez/data/dl2/melibea/dl2_melibea_BLLac.h5\n",
      "--> /fefs/aswg/workspace/juan.jimenez/data/dl2/melibea/dl2_melibea_Crab.h5\n"
     ]
    }
   ],
   "source": [
    "merged_files = glob.glob(merged_path)\n",
    "merged_files = [file for file in merged_files if '_to_' not in file]\n",
    "logger.info(f'\\n\\nThe merged files are taken from {merged_path}, and {len(merged_files)} are found:')\n",
    "for f in merged_files:\n",
    "    logger.info(f'--> {f}')\n",
    "    \n",
    "mean_files = glob.glob(mean_path)\n",
    "logger.info(f'\\n\\nThe mean files are taken from {mean_path}, and {len(mean_files)} are found:')\n",
    "for f in mean_files:\n",
    "    logger.info(f'--> {f}')\n",
    "    \n",
    "lst_files = glob.glob(lst_path)\n",
    "logger.info(f'\\n\\nThe lst-only files are taken from {lst_path}, and {len(lst_files)} are found:')\n",
    "for f in lst_files:\n",
    "    logger.info(f'--> {f}')\n",
    "    \n",
    "melibea_files = glob.glob(melibea_path)\n",
    "logger.info(f'\\n\\nThe melibea-only files are taken from {melibea_path}, and {len(melibea_files)} are found:')\n",
    "for f in melibea_files:\n",
    "    logger.info(f'--> {f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e64238b",
   "metadata": {},
   "source": [
    "# - Calculus of $\\theta^2$ data\n",
    "\n",
    "First of all for the `lstchain` data we need to compute `ra` and `dec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d4635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if compute_ra_dec == True:\n",
    "\n",
    "    logger.info('Computing RA and DEC for dl2 LST-lstchain files')\n",
    "    \n",
    "    # reading the dataframes\n",
    "    tmp_mean_dfs    = [pd.read_hdf(file, key='/events/parameters') for file in mean_files]\n",
    "    tmp_melibea_dfs = [pd.read_hdf(file, key='/events/parameters') for file in melibea_files]\n",
    "    tmp_lst_dfs     = [pd.read_hdf(file, key='/events/parameters') for file in lst_files]\n",
    "    \n",
    "    # iterating over lst ones\n",
    "    for tmp_df in tmp_lst_dfs:\n",
    "\n",
    "        # location of LST-1\n",
    "        location = EarthLocation.from_geodetic(-17.89139 * u.deg, 28.76139 * u.deg, 2184 * u.m) \n",
    "        # observation time\n",
    "        obstime = pd.to_datetime(tmp_df['dragon_time'], unit='s')\n",
    "        \n",
    "        # coordinate frame\n",
    "        horizon_frame = AltAz(location=location, obstime=obstime)    \n",
    "\n",
    "        # extracting pointing data\n",
    "        pointing_alt = u.Quantity(tmp_df['alt_tel'], u.rad, copy=False)\n",
    "        pointing_az  = u.Quantity(tmp_df['az_tel'],  u.rad, copy=False)\n",
    "        # in alt_az coordinates\n",
    "        pointing_direction = SkyCoord(alt=clip_alt(pointing_alt), az=pointing_az, frame=horizon_frame)\n",
    "        # in ra_dec\n",
    "        pointing_direction_icrs = pointing_direction.transform_to('icrs')\n",
    "        \n",
    "        # defining the camera coordinates frame\n",
    "        camera_frame = CameraFrame(focal_length=28 * u.m,\n",
    "                                   telescope_pointing=pointing_direction,\n",
    "                                   obstime=obstime,\n",
    "                                   location=location)     \n",
    "        camera_coords = SkyCoord(x=tmp_df['reco_src_x'], y=tmp_df['reco_src_y'], frame=camera_frame, unit=(u.m, u.m))\n",
    "        radec_coords  = camera_coords.transform_to(frame=ICRS)\n",
    "\n",
    "        # adding the ra-dec coordinates of pointing and events for lst data\n",
    "        tmp_df.loc[:,'reco_ra']      = radec_coords.ra.deg\n",
    "        tmp_df.loc[:,'reco_dec']     = radec_coords.dec.deg \n",
    "        tmp_df.loc[:,'pointing_ra']  = pointing_direction_icrs.ra.deg\n",
    "        tmp_df.loc[:,'pointing_dec'] = pointing_direction_icrs.dec.deg    \n",
    "\n",
    "        # setting run-event as indexes\n",
    "        tmp_df.set_index(['obs_id', 'event_id'], inplace=True)\n",
    "        tmp_df.sort_index(inplace=True)\n",
    "\n",
    "    # appending all dataframes in a unique array\n",
    "    all_dfs = [*tmp_mean_dfs, *tmp_melibea_dfs, *tmp_lst_dfs] \n",
    "\n",
    "    # deleting temporal dataframes\n",
    "    del tmp_lst_dfs, tmp_mean_dfs, tmp_melibea_dfs\n",
    "\n",
    "\n",
    "# only reading the files\n",
    "else:\n",
    "    logger.info(f'RA and DEC is already computed so only reading the existing files')\n",
    "    tmp_mean_dfs = [pd.read_hdf(file,    key='/events/parameters') for file in mean_files]\n",
    "    tmp_melibea_dfs = [pd.read_hdf(file, key='/events/parameters') for file in melibea_files]\n",
    "    tmp_lst_dfs = [pd.read_hdf(file,     key='/events/parameters') for file in lst_files]\n",
    "\n",
    "    # appending all dataframes in a unique array\n",
    "    all_dfs = [*tmp_mean_dfs, *tmp_melibea_dfs, *tmp_lst_dfs] \n",
    "    \n",
    "    # deleting temporal dataframes\n",
    "    del tmp_lst_dfs, tmp_mean_dfs, tmp_melibea_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9684bc6e",
   "metadata": {},
   "source": [
    "Iterating over all files and computing $\\theta^2$ values for `ON` and `OFF` regions. Is defined as, \n",
    "\n",
    "$$\\theta^2 (\\text{ON/OFF})= \\text{angular_distance}(\\text{event_dir}, \\text{ON/OFF_dir})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7392e9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# empty arrays\n",
    "all_dfs_with_theta2, all_files_with_theta2 = [], []\n",
    "\n",
    "# extracting sky coordinates of the source we are studing\n",
    "on_coord = SkyCoord.from_name(source_name, frame='icrs')\n",
    "logger.info(f'ON coordinate ({source_name}):\\n{on_coord}')\n",
    "    \n",
    "# iterate over all dataframes\n",
    "for file, df in zip(np.concatenate([mean_files, melibea_files, lst_files]), all_dfs):\n",
    "    logger.info(f'\\nFile: {file}')\n",
    "\n",
    "    # create a figure for each file\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    \n",
    "    # now extracting off regions\n",
    "    logger.info(f'\\nNumber of OFF regions: {n_regions_off}')\n",
    "    # loop over every observation ID\n",
    "    obs_ids = np.unique(df.index.get_level_values('obs_id'))\n",
    "    for obs_id in obs_ids:\n",
    "\n",
    "        # filtering dataframe by runs\n",
    "        df_events = df.query(f'obs_id == {obs_id}')\n",
    "\n",
    "        # extracting event coordinates\n",
    "        event_coords = SkyCoord(\n",
    "            u.Quantity(df_events['reco_ra'], unit='deg'),\n",
    "            u.Quantity(df_events['reco_dec'], unit='deg'),\n",
    "            frame='icrs',)\n",
    "        # extracting mean values\n",
    "        pnt_ra_mean  = df_events['pointing_ra'].mean()  * u.deg\n",
    "        pnt_dec_mean = df_events['pointing_dec'].mean() * u.deg\n",
    "\n",
    "        # plot the pointing mean direction\n",
    "        ax.scatter(pnt_ra_mean, pnt_dec_mean, marker='x', s=300, color='k', linewidths=1)\n",
    "\n",
    "        # calculate the angular distances from the ON region\n",
    "        theta2_on = on_coord.separation(event_coords).to_value('deg') ** 2\n",
    "\n",
    "        # appending the data to the total dataframe\n",
    "        df.loc[(obs_id, slice(None)), 'theta2_on'] = theta2_on\n",
    "\n",
    "        # calculate the OFF coordinates\n",
    "        off_coords = calculate_off_coordinates(\n",
    "            pointing_ra=pnt_ra_mean,\n",
    "            pointing_dec=pnt_dec_mean,\n",
    "            on_coord_ra=on_coord.ra,\n",
    "            on_coord_dec=on_coord.dec,\n",
    "            n_regions=n_regions_off,)\n",
    "\n",
    "        # iterate over all off regions\n",
    "        for i_off, off_coord in off_coords.items():\n",
    "\n",
    "            # calculate the angular distance from the OFF coordinate\n",
    "            theta2_off = off_coord.separation(event_coords).to_value('deg') ** 2\n",
    "\n",
    "            # appending the data to the total dataframe\n",
    "            df.loc[(obs_id, slice(None)), f'theta2_off{i_off}'] = theta2_off\n",
    "\n",
    "            # plot the OFF coordinate\n",
    "            ax.scatter(off_coord.ra.to('deg'), off_coord.dec.to('deg'), marker='o', s=500, facecolors='none', edgecolors='grey')\n",
    "\n",
    "    # legend markers\n",
    "    ax.scatter([], [], marker='o', s=500, facecolors='none', edgecolors='grey', label='OFF source')   \n",
    "    ax.scatter([], [], marker='x', s=300, color='k', linewidths=1,              label='Pointing')\n",
    "    # plot the ON coordinate\n",
    "    ax.scatter(on_coord.ra.to('deg'), on_coord.dec.to('deg'), label=f'ON, {source_name}', marker='*', s=400, color='deeppink')\n",
    "\n",
    "    ax.set_xlabel('RA [deg]')\n",
    "    ax.set_ylabel('Dec [deg]')\n",
    "    # converting the coordinated to degrees and adding 2 degrees by both sides\n",
    "    xlim = on_coord.ra.to_value('deg')  + np.array([1, -1])\n",
    "    ylim = on_coord.dec.to_value('deg') + np.array([-1, 1])\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # saving the dataframes and the nam of the file\n",
    "    all_dfs_with_theta2.append(df.copy())\n",
    "    all_files_with_theta2.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a9c3d0",
   "metadata": {},
   "source": [
    "Now we save again the dataframes in the respective files, updating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, file in zip(all_dfs_with_theta2, all_files_with_theta2):\n",
    "    logger.info(f'Overwritting {file} with theta2 data.\\n')\n",
    "    df.to_hdf(file, key='/events/parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07627ea0",
   "metadata": {},
   "source": [
    "# - Adding more geometrical data and coordinates\n",
    "- Adding zenith distance, because data is given in `alt` coordinates, we can convert directly using:\n",
    "$$\\text{zd} = 90 - \\text{alt}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1575e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# puttig all files and data together\n",
    "all_files = [*merged_files, *mean_files, *melibea_files, *lst_files]\n",
    "all_dfs   = [pd.read_hdf(file, key='/events/parameters') for file in all_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fcd410",
   "metadata": {},
   "source": [
    "Now we can add the data and change some columns names to maintain consistency of all dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, df in zip(all_files, all_dfs):\n",
    "    \n",
    "    logger.info(f'Writting coordinates for file {file}\\n')\n",
    "    \n",
    "    # in lst files we rename the variables in order to maintain consistency\n",
    "    if file in lst_files:\n",
    "        df.rename({'alt_tel':'pointing_alt'}, axis=1, inplace=True)\n",
    "        df.rename({'az_tel':'pointing_az'},   axis=1, inplace=True)\n",
    "        \n",
    "    # adding pointing direction\n",
    "    df.loc[:,'pointing_zd'] = df['pointing_alt'] - 90.\n",
    "    \n",
    "    # for melibea files we do not have the events information (we have it for both telescopes, \n",
    "    # and we do not inport all this information)\n",
    "    if file not in melibea_files:\n",
    "        df.loc[:,'reco_zd'] = df['reco_alt'] - 90.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc415896",
   "metadata": {},
   "source": [
    "Now we save again the dataframes in the respective files, updating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df, file in zip(all_dfs, all_files):\n",
    "    logger.info(f'Overwritting {file} with zenith distance data.\\n')\n",
    "    df.to_hdf(file, key='/events/parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ad0fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
