{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d8cc7b",
   "metadata": {},
   "source": [
    "Import packages and setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c03ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Study of the source: BLLac\n",
      "\n",
      "All data taken from the path: /fefs/aswg/workspace/abelardo.moralejo/jjimenez_master/Crab_LST1/DL2/dl2_*.h5\n",
      "\n",
      "Reference stereo data taken from the file: /fefs/aswg/workspace/juan.jimenez/data/dl2/stereo_mean/dl2_mean_BLLac_total.3tel.h5\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, logging, sys, glob\n",
    "from astropy import units as u\n",
    "from lstchain.reco.utils import get_effective_time\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# --- logging --- #\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# location of the scripts\n",
    "sys.path.insert(0, '/fefs/aswg/workspace/juan.jimenez/stereo_analysis/scripts')\n",
    "import auxiliar as aux\n",
    "import geometry as geom\n",
    "aux.params()\n",
    "\n",
    "# --- parameters --- #\n",
    "# name of the studied source\n",
    "source_name = 'BLLac'\n",
    "\n",
    "\n",
    "# tablename to open lst hdf files\n",
    "tablename = '/dl2/event/telescope/parameters/LST_LSTCam'\n",
    "# columns that are extracted\n",
    "columns = ['obs_id', 'event_id', 'intensity', 'x', 'y', 'r', 'phi', 'length', 'width', 'psi', 'time_gradient', 'intercept',\n",
    "           'alt_tel', 'az_tel', 'dragon_time', 'delta_t', 'reco_energy', 'reco_alt', 'reco_az', 'gammaness', 'reco_src_x',\n",
    "           'reco_src_y', 'reco_disp_norm']\n",
    "# ------------------ #\n",
    "\n",
    "# --- file paths --- #\n",
    "root_path = '/fefs/aswg/workspace/juan.jimenez/data'\n",
    "\n",
    "common_data_path = f'/fefs/aswg/workspace/juan.jimenez/stereo_analysis/config_files/common_data{source_name}.txt'\n",
    "\n",
    "stereo_mean_path = f'{root_path}/dl2/stereo_mean/dl2_mean_{source_name}_total.3tel.h5'\n",
    "\n",
    "lst_dl2_path     = f'/fefs/aswg/workspace/abelardo.moralejo/jjimenez_master/Crab_LST1/DL2/dl2_*.h5'\n",
    "lst_out_path     = f'{root_path}/dl2/lst/'\n",
    "# ------------------ #\n",
    "\n",
    "# --- calibration parameters --- #\n",
    "nominal_focal = 28       * u.m\n",
    "focal         = 29.30565 * u.m\n",
    "aberration_correction = focal / nominal_focal\n",
    "\n",
    "logger.info(f'Study of the source: {source_name}')\n",
    "logger.info(f'\\nAll data taken from the path: {lst_dl2_path}')\n",
    "logger.info(f'\\nReference stereo data taken from the file: {stereo_mean_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d500720e",
   "metadata": {},
   "source": [
    "First of all we find the files and find the streo events to discard the non-stereo events from the LST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53bf1b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 68 files in /fefs/aswg/workspace/abelardo.moralejo/jjimenez_master/Crab_LST1/DL2/dl2_*.h5\n",
      "Opening the file...\n",
      "/fefs/aswg/workspace/juan.jimenez/stereo_analysis/config_files/common_dataBLLac.txt\n",
      "\n",
      "Found 27 runs\n",
      "\n",
      "Opening the file...\n",
      "/fefs/aswg/workspace/juan.jimenez/data/dl2/stereo_mean/dl2_mean_BLLac_total.3tel.h5\n"
     ]
    }
   ],
   "source": [
    "# --- reading dataset --- #\n",
    "dataset = glob.glob(lst_dl2_path)\n",
    "dataset.sort()\n",
    "logger.info(f'Found {len(dataset)} files in {lst_dl2_path}')\n",
    "\n",
    "# --- lst runs we want --- #\n",
    "# first of all we can read the common data file\n",
    "logger.info(f'Opening the file...\\n{common_data_path}\\n')\n",
    "\n",
    "# saving the same-night runs comparing LST runs with all MAGIC\n",
    "jobs_list = np.loadtxt(common_data_path, dtype='str')\n",
    "logger.info(f'Found {len(jobs_list)} runs\\n')\n",
    "\n",
    "# extracting all LST runs\n",
    "lst_runs = []\n",
    "for job in jobs_list:\n",
    "    midindex = job.find('-')\n",
    "    lst_runs.append(int(job[:midindex]))\n",
    "    \n",
    "logger.info(f'Opening the file...\\n{stereo_mean_path}')\n",
    "df_mean = pd.read_hdf(stereo_mean_path)\n",
    "lst_events = df_mean['total_id'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3e454",
   "metadata": {},
   "source": [
    "Now we iterate over all files given in the path, and after we join them. Finally the data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "751429c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iterating over all filenames 27 runs\n",
      "\n",
      "Completed (100%)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23234/340995136.py\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# concatenating the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtable\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# --- create .h5 file --- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/magic-lst1/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/magic-lst1/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;36m1\u001b[0m   \u001b[0;36m3\u001b[0m   \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \"\"\"\n\u001b[0;32m--> 368\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/magic-lst1/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# --- iterating over all files --- #\n",
    "logger.info(f'\\nIterating over all filenames {len(lst_runs)} runs\\n')\n",
    "\n",
    "table, t_eff, t_elapsed = [], 0, 0\n",
    "\n",
    "for file, i in zip(dataset, range(len(dataset))):\n",
    "\n",
    "    if int(file[-8:-3]) in lst_runs:\n",
    "        \n",
    "        logger.info(f'Reading {file}, ({i/len(dataset)*100:.1f}%)')\n",
    "        # temporal table with only the requested columns\n",
    "        tb = pd.read_hdf(file, tablename)[columns]\n",
    "        \n",
    "        obs_id_array   = tb['obs_id'].to_numpy().astype(str)\n",
    "        event_id_array = tb['event_id'].to_numpy().astype(str)\n",
    "        tb.loc[:,'total_id'] = np.char.add(obs_id_array, np.char.add('.',event_id_array))\n",
    "        \n",
    "        tb = tb.query(f'total_id in @lst_events', inplace=False)\n",
    "    \n",
    "        if len(tb) > 0:\n",
    "            # getting the times of the events\n",
    "            lt, et = get_effective_time(tb)\n",
    "            t_eff     += lt\n",
    "            t_elapsed += et\n",
    "\n",
    "            # appending to main dataframes\n",
    "            logger.info(f'Coincidences for run {int(file[-8:-3])} are {len(tb)}')\n",
    "            table.append(tb)\n",
    "        else:\n",
    "            logger.info(f'No coincidences for run {int(file[-8:-3])}')\n",
    "\n",
    "logger.info(f'Completed (100%)\\n\\n')\n",
    "\n",
    "# concatenating the dataframe\n",
    "table  = pd.concat(table)\n",
    "\n",
    "# --- create .h5 file --- #\n",
    "logger.info(f'\\nCreating .h5 files and storing in {lst_out_path}')\n",
    "table.to_hdf(os.path.join(lst_out_path, f'dl2_lst_{source_name}.h5'), key='events/parameters')\n",
    "\n",
    "# displaying an example of few events\n",
    "display(table.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a44ab",
   "metadata": {},
   "source": [
    "In the case the dataframe already exists and you only want to read it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- reading in the case it is already created --- #\n",
    "table = pd.read_hdf(os.path.join(lst_out_path, f'dl2_lst_{source_name}.h5'), key='events/parameters')\n",
    "\n",
    "# and printing an example of both dataframes\n",
    "logger.info(f'Total dataframe for LST events processed with lstchain: dl2_lst_{source_name}.h5')\n",
    "logger.info(f'A total of {int(len(table))} events found:')\n",
    "display(table.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce6eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
