{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d8cc7b",
   "metadata": {},
   "source": [
    "Import packages and setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c03ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, logging, sys, glob\n",
    "from astropy import units as u\n",
    "from lstchain.reco.utils import get_effective_time\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# --- logging --- #\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# location of the scripts\n",
    "sys.path.insert(0, '/fefs/aswg/workspace/juan.jimenez/stereo_analysis/scripts')\n",
    "import auxiliar as aux\n",
    "import geometry as geom\n",
    "aux.params()\n",
    "\n",
    "# --- parameters --- #\n",
    "# name of the studied source\n",
    "source_name = 'Crab'\n",
    "\n",
    "\n",
    "# tablename to open lst hdf files\n",
    "tablename = '/dl2/event/telescope/parameters/LST_LSTCam'\n",
    "# columns that are extracted\n",
    "columns = ['obs_id', 'event_id', 'intensity', 'x', 'y', 'r', 'phi', 'length', 'width', 'psi', 'time_gradient', 'intercept',\n",
    "           'alt_tel', 'az_tel', 'dragon_time', 'delta_t', 'reco_energy', 'reco_alt', 'reco_az', 'gammaness', 'reco_src_x',\n",
    "           'reco_src_y', 'reco_disp_norm']\n",
    "# ------------------ #\n",
    "\n",
    "# --- file paths --- #\n",
    "root_path = '/fefs/aswg/workspace/juan.jimenez/data'\n",
    "\n",
    "common_data_path = f'/fefs/aswg/workspace/juan.jimenez/stereo_analysis/config_files/common_data{source_name}.txt'\n",
    "\n",
    "stereo_mean_path = f'{root_path}/dl2/stereo_mean/dl2_mean_{source_name}_total.3tel.h5'\n",
    "\n",
    "lst_dl2_path     = f'/fefs/aswg/workspace/abelardo.moralejo/jjimenez_master/Crab_LST1/DL2/dl2_*.h5'\n",
    "lst_out_path     = f'{root_path}/dl2/lst/'\n",
    "# ------------------ #\n",
    "\n",
    "# --- calibration parameters --- #\n",
    "nominal_focal = 28       * u.m\n",
    "focal         = 29.30565 * u.m\n",
    "aberration_correction = focal / nominal_focal\n",
    "\n",
    "logger.info(f'Study of the source: {source_name}')\n",
    "logger.info(f'\\nAll data taken from the path: {lst_dl2_path}')\n",
    "logger.info(f'\\nReference stereo data taken from the file: {stereo_mean_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d500720e",
   "metadata": {},
   "source": [
    "First of all we find the files and find the streo events to discard the non-stereo events from the LST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf1b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- reading dataset --- #\n",
    "dataset = glob.glob(lst_dl2_path)\n",
    "dataset.sort()\n",
    "logger.info(f'Found {len(dataset)} files in {lst_dl2_path}')\n",
    "\n",
    "# --- lst runs we want --- #\n",
    "# first of all we can read the common data file\n",
    "logger.info(f'Opening the file...\\n{common_data_path}\\n')\n",
    "\n",
    "# saving the same-night runs comparing LST runs with all MAGIC\n",
    "jobs_list = np.loadtxt(common_data_path, dtype='str')\n",
    "logger.info(f'Found {len(jobs_list)} runs\\n')\n",
    "\n",
    "# extracting all LST runs\n",
    "lst_runs = []\n",
    "for job in jobs_list:\n",
    "    midindex = job.find('-')\n",
    "    lst_runs.append(int(job[:midindex]))\n",
    "    \n",
    "logger.info(f'Opening the file...\\n{stereo_mean_path}')\n",
    "df_mean = pd.read_hdf(stereo_mean_path)\n",
    "lst_events = df_mean['total_id'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3e454",
   "metadata": {},
   "source": [
    "Now we iterate over all files given in the path, and after we join them. Finally the data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751429c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- iterating over all files --- #\n",
    "logger.info(f'\\nIterating over all filenames {len(lst_runs)} runs\\n')\n",
    "\n",
    "table, t_eff, t_elapsed = [], 0, 0\n",
    "\n",
    "for file, i in zip(dataset, range(len(dataset))):\n",
    "\n",
    "    if int(file[-8:-3]) in lst_runs:\n",
    "        \n",
    "        logger.info(f'Reading {file}, ({i/len(dataset)*100:.1f}%)')\n",
    "        # temporal table with only the requested columns\n",
    "        tb = pd.read_hdf(file, tablename)[columns]\n",
    "        \n",
    "        obs_id_array   = tb['obs_id'].to_numpy().astype(str)\n",
    "        event_id_array = tb['event_id'].to_numpy().astype(str)\n",
    "        tb.loc[:,'total_id'] = np.char.add(obs_id_array, np.char.add('.',event_id_array))\n",
    "        \n",
    "        tb = tb.query(f'total_id in @lst_events', inplace=False)\n",
    "    \n",
    "        if len(tb) > 0:\n",
    "            # getting the times of the events\n",
    "            lt, et = get_effective_time(tb)\n",
    "            t_eff     += lt\n",
    "            t_elapsed += et\n",
    "\n",
    "            # appending to main dataframes\n",
    "            logger.info(f'Coincidences for run {int(file[-8:-3])} are {len(tb)}')\n",
    "            table.append(tb)\n",
    "        else:\n",
    "            logger.info(f'No coincidences for run {int(file[-8:-3])}')\n",
    "\n",
    "logger.info(f'Completed (100%)\\n\\n')\n",
    "\n",
    "# concatenating the dataframe\n",
    "table  = pd.concat(table)\n",
    "\n",
    "# --- create .h5 file --- #\n",
    "logger.info(f'\\nCreating .h5 files and storing in {lst_out_path}')\n",
    "table.to_hdf(os.path.join(lst_out_path, f'dl2_lst_{source_name}.h5'), key='events/parameters')\n",
    "\n",
    "# displaying an example of few events\n",
    "display(table.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a44ab",
   "metadata": {},
   "source": [
    "In the case the dataframe already exists and you only want to read it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- reading in the case it is already created --- #\n",
    "table = pd.read_hdf(os.path.join(lst_out_path, f'dl2_lst_{source_name}.h5'), key='events/parameters')\n",
    "\n",
    "# and printing an example of both dataframes\n",
    "logger.info(f'Total dataframe for LST events processed with lstchain: dl2_lst_{source_name}.h5')\n",
    "logger.info(f'A total of {int(len(table))} events found:')\n",
    "display(table.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce6eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
